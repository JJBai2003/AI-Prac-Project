{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLEASE READ: We will be using this to visualize the output of the model implementations. The impl.py file can be used for writing the detailed implementation of the functions, or any other helper functions that we might find useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing some thoughts:\n",
    "1. Finetuning YOLO or training our own classification model:\n",
    "    a. need a database for photos\n",
    "    b. \n",
    "2. Finetuning some NLP model or training our own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset \n",
    "path = \"path to the dataset\"\n",
    "dataset = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some hyper parameters\n",
    "batch_size = 32\n",
    "train_ratio = 0.7\n",
    "val_ration = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# splitting the dataset\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "val_size = int(len(dataset) * val_ration)\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# creating the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_data_loader, criterion):\n",
    "  \"\"\"\n",
    "  Validate the model on the validation dataset.\n",
    "\n",
    "  Inputs:\n",
    "  model (torch.nn.Module): The deep learning model to be trained.\n",
    "  val_data_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "  criterion (torch.nn.Module): Loss function to compute the training loss.\n",
    "\n",
    "  Returns:\n",
    "  Validation loss (float)\n",
    "  \"\"\"\n",
    "  val_running_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(val_data_loader, 0):\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_running_loss += loss.item()\n",
    "\n",
    "  return val_running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, val_data_loader, criterion, optimizer, epochs):\n",
    "    \"\"\"\n",
    "    Train the model on the training dataset.\n",
    "    Inputs:\n",
    "    model (torch.nn.Module): The deep learning model to be trained.\n",
    "    data_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    val_data_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "    criterion (torch.nn.Module): Loss function to compute the training loss.\n",
    "    optimizer (torch.optim.Optimizer): Optimizer used for updating the model parameters.\n",
    "    epochs (int): Number of training epochs.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of (train_loss_arr, val_loss_arr), an array of the training and validation\n",
    "    losses at each epoch\n",
    "    \"\"\"\n",
    "    train_loss_arr = []\n",
    "    val_loss_arr = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, b in enumerate(data_loader):\n",
    "          optimizer.zero_grad()\n",
    "          inputs, labels = b\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, labels)\n",
    "          running_loss += loss.item() * inputs.shape[0]\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "        train_loss_arr.append(running_loss / train_size)\n",
    "        val_loss_arr.append(val(model,val_data_loader,criterion))\n",
    "\n",
    "\n",
    "    print('Training finished.')\n",
    "    return train_loss_arr, val_loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing hyperparameters for the layers\n",
    "input_dim = 4\n",
    "hidden_layer_1 = 128\n",
    "hidden_layer_2 = 64\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the structure of the model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_layer_1)\n",
    "        self.fc2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.fc3 = nn.Linear(hidden_layer_2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
